{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cbdeacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#16/8/24 This script aims to test ways of fixing class imbalance\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "\n",
    "seed = 81\n",
    "#Data import\n",
    "#df = pd.read_csv('/Users/james/Documents/Honours/Data/Fingerprints/SR-ATAD5_Morganfp.csv')\n",
    "df = pd.read_csv('/Users/james/Documents/Honours/Data/Chemopy/datasets/Cardiotoxicity-30_Chemopy.csv')\n",
    "toxvals = (df['Toxicity_Value'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d52284a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Toxicity_Value</th>\n",
       "      <th>Weight</th>\n",
       "      <th>nH</th>\n",
       "      <th>nHal</th>\n",
       "      <th>nHet</th>\n",
       "      <th>nHA</th>\n",
       "      <th>nF</th>\n",
       "      <th>nCl</th>\n",
       "      <th>nBr</th>\n",
       "      <th>nI</th>\n",
       "      <th>...</th>\n",
       "      <th>VSAEstate0</th>\n",
       "      <th>VSAEstate1</th>\n",
       "      <th>VSAEstate2</th>\n",
       "      <th>VSAEstate3</th>\n",
       "      <th>VSAEstate4</th>\n",
       "      <th>VSAEstate5</th>\n",
       "      <th>VSAEstate6</th>\n",
       "      <th>VSAEstate7</th>\n",
       "      <th>VSAEstate8</th>\n",
       "      <th>VSAEstate9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>148.150</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.547454</td>\n",
       "      <td>13.559583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.539352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.115231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.905046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>392.198</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>79.365588</td>\n",
       "      <td>13.706120</td>\n",
       "      <td>6.623437</td>\n",
       "      <td>3.618548</td>\n",
       "      <td>-4.964313</td>\n",
       "      <td>0.501815</td>\n",
       "      <td>-4.874915</td>\n",
       "      <td>-0.226280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>249.040</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.800942</td>\n",
       "      <td>8.238624</td>\n",
       "      <td>11.965103</td>\n",
       "      <td>0.176914</td>\n",
       "      <td>5.134145</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.906493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>388.264</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.426309</td>\n",
       "      <td>14.554939</td>\n",
       "      <td>20.051051</td>\n",
       "      <td>2.034770</td>\n",
       "      <td>-1.100900</td>\n",
       "      <td>17.734904</td>\n",
       "      <td>-0.034407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>446.378</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.779758</td>\n",
       "      <td>16.071759</td>\n",
       "      <td>20.445076</td>\n",
       "      <td>2.038770</td>\n",
       "      <td>1.029534</td>\n",
       "      <td>19.265172</td>\n",
       "      <td>3.943649</td>\n",
       "      <td>4.134694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.458255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>1</td>\n",
       "      <td>362.287</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.126948</td>\n",
       "      <td>18.888857</td>\n",
       "      <td>11.077501</td>\n",
       "      <td>3.931990</td>\n",
       "      <td>0.196565</td>\n",
       "      <td>19.636096</td>\n",
       "      <td>5.457594</td>\n",
       "      <td>2.351115</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>0</td>\n",
       "      <td>439.753</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.116340</td>\n",
       "      <td>26.333584</td>\n",
       "      <td>15.836239</td>\n",
       "      <td>3.421882</td>\n",
       "      <td>-0.736528</td>\n",
       "      <td>12.776628</td>\n",
       "      <td>4.340082</td>\n",
       "      <td>5.500209</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.356008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>1</td>\n",
       "      <td>482.331</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>51.952916</td>\n",
       "      <td>19.354981</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.824498</td>\n",
       "      <td>-1.218842</td>\n",
       "      <td>13.241029</td>\n",
       "      <td>-0.196909</td>\n",
       "      <td>4.458993</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>1</td>\n",
       "      <td>403.311</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.162470</td>\n",
       "      <td>21.379596</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.203739</td>\n",
       "      <td>0.029218</td>\n",
       "      <td>13.726178</td>\n",
       "      <td>9.481959</td>\n",
       "      <td>3.850174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>1</td>\n",
       "      <td>465.380</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>36.453926</td>\n",
       "      <td>19.492576</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.035855</td>\n",
       "      <td>0.503007</td>\n",
       "      <td>13.520743</td>\n",
       "      <td>3.679405</td>\n",
       "      <td>4.918677</td>\n",
       "      <td>-2.854189</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1547 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Toxicity_Value   Weight  nH  nHal  nHet  nHA  nF  nCl  nBr  nI  ...  \\\n",
       "0                  1  148.150   4     0     5   10   0    0    0   0  ...   \n",
       "1                  0  392.198  16     6    16   28   6    0    0   0  ...   \n",
       "2                  0  249.040   7     2     9   16   0    2    0   0  ...   \n",
       "3                  1  388.264  21     2    24   30   2    0    0   0  ...   \n",
       "4                  1  446.378  28     0    28   34   0    0    0   0  ...   \n",
       "...              ...      ...  ..   ...   ...  ...  ..  ...  ...  ..  ...   \n",
       "1542               1  362.287  24     0    23   29   0    0    0   0  ...   \n",
       "1543               0  439.753  27     1    25   33   0    1    0   0  ...   \n",
       "1544               1  482.331  35     4    29   37   4    0    0   0  ...   \n",
       "1545               1  403.311  29     1    26   32   1    0    0   0  ...   \n",
       "1546               1  465.380  34     1    27   35   1    0    0   0  ...   \n",
       "\n",
       "      VSAEstate0  VSAEstate1  VSAEstate2  VSAEstate3  VSAEstate4  VSAEstate5  \\\n",
       "0       0.547454   13.559583    0.000000    1.539352    0.000000    0.000000   \n",
       "1      79.365588   13.706120    6.623437    3.618548   -4.964313    0.501815   \n",
       "2       0.000000    3.800942    8.238624   11.965103    0.176914    5.134145   \n",
       "3      26.426309   14.554939   20.051051    2.034770   -1.100900   17.734904   \n",
       "4       6.779758   16.071759   20.445076    2.038770    1.029534   19.265172   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1542    2.126948   18.888857   11.077501    3.931990    0.196565   19.636096   \n",
       "1543    2.116340   26.333584   15.836239    3.421882   -0.736528   12.776628   \n",
       "1544   51.952916   19.354981    0.000000    4.824498   -1.218842   13.241029   \n",
       "1545   15.162470   21.379596    0.000000    5.203739    0.029218   13.726178   \n",
       "1546   36.453926   19.492576    0.000000    5.035855    0.503007   13.520743   \n",
       "\n",
       "      VSAEstate6  VSAEstate7  VSAEstate8  VSAEstate9  \n",
       "0       3.115231    0.000000    0.000000    4.905046  \n",
       "1      -4.874915   -0.226280    0.000000    0.000000  \n",
       "2       0.000000    0.000000    0.000000   11.906493  \n",
       "3      -0.034407    0.000000    0.000000    0.000000  \n",
       "4       3.943649    4.134694    0.000000    1.458255  \n",
       "...          ...         ...         ...         ...  \n",
       "1542    5.457594    2.351115    0.000000    0.000000  \n",
       "1543    4.340082    5.500209    0.000000    6.356008  \n",
       "1544   -0.196909    4.458993    0.000000    0.000000  \n",
       "1545    9.481959    3.850174    0.000000    0.000000  \n",
       "1546    3.679405    4.918677   -2.854189    0.000000  \n",
       "\n",
       "[1547 rows x 201 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a1568ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#K fold partioning\n",
    "\n",
    "#Given imbalanced data\n",
    "#split majority class into K partitions where K is (Number of majority class) / (number of minority class)\n",
    "#each partition is the size of the minority class\n",
    "#Each parition is then modelled against minority class so K models are made\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfaece81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples = 1547\n",
      "Positives in data: 1284\n",
      "Negatives in data: 263\n",
      "Partitions Needed: 4.88212927756654\n"
     ]
    }
   ],
   "source": [
    "#Determine Degree of Class Imbalance\n",
    "posvals = 0\n",
    "negvals = 0\n",
    "loops = 0\n",
    "neglist = []\n",
    "poslist = []\n",
    "for value in toxvals:\n",
    "    if value == 1:\n",
    "        posvals += 1\n",
    "        poslist.append(loops)\n",
    "    else:\n",
    "        negvals += 1\n",
    "        neglist.append(loops)\n",
    "        \n",
    "    loops += 1\n",
    "\n",
    "print('Total samples =', (negvals + posvals))\n",
    "print('Positives in data:', posvals)\n",
    "print('Negatives in data:', negvals)\n",
    "big = posvals\n",
    "small = negvals\n",
    "if negvals > posvals:\n",
    "    big = negvals\n",
    "    small = posvals \n",
    "print('Partitions Needed:', (big / small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e82fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n"
     ]
    }
   ],
   "source": [
    "#Find Model Performance on Imbalanced Set\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "sys.path.insert(1, '/Users/james/Documents/Honours/Python')\n",
    "from Function_Repo import metriccalc \n",
    "\n",
    "df = pd.read_csv('/Users/james/Documents/Honours/Data/Fingerprints/SR-ATAD5_Morganfp.csv')\n",
    "#df = pd.read_csv('/Users/james/Documents/Honours/Data/Fingerprints/Ames_Mutagenicity_Morganfp.csv')\n",
    "#df.drop(columns=['SMILES'], inplace=True)\n",
    "df = df.dropna()\n",
    "dfarray = df.to_numpy()\n",
    "\n",
    "dfarray, tempset = train_test_split(dfarray, test_size=0.2, \n",
    "                                    random_state=seed, stratify = df['Toxicity_Value'])\n",
    "\n",
    "size = len(dfarray) / 5\n",
    "splitsize = math.ceil(size)\n",
    "empty = [[] for _ in range(5)]\n",
    "splits = []\n",
    "for list in empty:\n",
    "    splits.append(list)\n",
    "\n",
    "loops = 0\n",
    "currsplit = 0\n",
    "#Results in a list of 5 lists that each contain 1/5 of the targetdata\n",
    "for row in dfarray:\n",
    "    splits[currsplit].append(row)\n",
    "    if loops == splitsize:\n",
    "        loops = 0\n",
    "        currsplit = currsplit + 1\n",
    "    loops = loops + 1\n",
    "\n",
    "folds = []\n",
    "for split in splits:\n",
    "    temp = pd.DataFrame(split)\n",
    "    folds.append(temp)\n",
    "\n",
    "model_list = []\n",
    "validlist = []\n",
    "totalmetrics = []\n",
    "testdat = []\n",
    "#For loop that uses each fold once for valid/testing and the rest for training\n",
    "#Each 'split' in the range corresponds to the set used for test/validation with the other 4 for training\n",
    "iteration = 1\n",
    "print('========================================')\n",
    "for split in range(0,5):\n",
    "    #Set creation\n",
    "    trainlist = [df for i, df in enumerate(folds) if i != split]\n",
    "    trainset = pd.concat(trainlist, axis=0)\n",
    "    testset, validset = train_test_split(folds[split], test_size=0.5, random_state=seed)\n",
    "\n",
    "    ytrain = trainset[0].values\n",
    "    xtrain = trainset.iloc[:, 1:]\n",
    "\n",
    "    ytest = testset[0].values\n",
    "    xtest = testset.iloc[:, 1:]\n",
    "\n",
    "    yvalid = validset[0].values\n",
    "    xvalid = validset.iloc[:, 1:]\n",
    "\n",
    "    #lists of metric values\n",
    "    mcclist = []\n",
    "    bestmetrics = 1\n",
    "    maxval = 0\n",
    "    for mtry in range(1, 50):\n",
    "        #using mtry as the adjusted hyperparameter creates a series of random forests\n",
    "        rf = RandomForestClassifier(n_estimators=mtry, criterion='entropy', max_depth=None, \n",
    "                                min_samples_split=2, min_samples_leaf=1, \n",
    "                                min_weight_fraction_leaf=0.0, max_features='sqrt', \n",
    "                                max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "                                bootstrap=True, oob_score=False, n_jobs= 4, random_state=seed, \n",
    "                                verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
    "\n",
    "        model= rf.fit(xtrain, ytrain)\n",
    "        preds = model.predict(xtest)\n",
    "        #calculate metric (mcc)\n",
    "        mcc = metriccalc(preds, ytest)[12]\n",
    "        mcclist.append(mcc)\n",
    "        if mcc > maxval:\n",
    "            maxval = mcc\n",
    "            bestmetrics = mtry\n",
    "    #store best model for the given fold and plot the metric vs mcc value\n",
    "    rf = RandomForestClassifier(n_estimators=bestmetrics, criterion='entropy', max_depth=None, \n",
    "                                min_samples_split=2, min_samples_leaf=1, \n",
    "                                min_weight_fraction_leaf=0.0, max_features='sqrt', \n",
    "                                max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "                                bootstrap=True, oob_score=False, n_jobs= 4, random_state=seed, \n",
    "                                verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
    "    model_list.append(rf)\n",
    "    testdat.append(maxval)\n",
    "    totalmetrics.append(mcclist)\n",
    "\n",
    "    #check models onto validation set, printing various metrics\n",
    "    model= rf.fit(xtrain, ytrain)\n",
    "    preds = model.predict(xvalid)\n",
    "    results = metriccalc(preds, yvalid)\n",
    "    validlist.append(results)\n",
    "    print('for fold', split + 1, 'test set mcc of', maxval, 'valid set mcc of', results[12])\n",
    "\n",
    "    iteration = iteration + 1\n",
    "\n",
    "    #get x and y values for the final validation set\n",
    "\n",
    "toxvals = []\n",
    "fingerprints = []\n",
    "for row in tempset:\n",
    "    toxvals.append(row[0])\n",
    "    fingerprints.append(row[1:])\n",
    "\n",
    "#calculates consensus of models on each fingerprint in the final validation set\n",
    "consensuslist = []\n",
    "predictions = []\n",
    "for fp in fingerprints:\n",
    "    consensus = -1\n",
    "    fp = fp.reshape(1, -1)\n",
    "    #appends each model's prediction to a list\n",
    "    predictions = []\n",
    "    predlist = []\n",
    "    for model in model_list:\n",
    "        preds = model.predict(fp)\n",
    "        predictions.append(preds)\n",
    "        predlist.append(preds)\n",
    "    predictions.append(predlist)\n",
    "\n",
    "    #finds number of 0s in the prediction list\n",
    "    zercount = 0\n",
    "    for num in predictions:\n",
    "        if num == 0:\n",
    "            zercount = zercount + 1\n",
    "    #as there are 5 models, if there are less than 3 0s predicted, the consensus is 1\n",
    "    if zercount < 3:\n",
    "        consensus = 1\n",
    "    else:\n",
    "        consensus = 0\n",
    "    consensuslist.append(consensus)\n",
    "#calculate and print metrics\n",
    "results = metriccalc(consensuslist, toxvals)\n",
    "print('\\nvalidation metrics of:')\n",
    "print('positives in data', results[0])\n",
    "print('negatives in data', results[1])\n",
    "print('net accuracy =', results[6])\n",
    "print('mcc =',results[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc382a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#as seen the results using the whole dataset is suboptimal at best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a487b6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Partioning dominant results into portions of 253 (number of non-dominant samples)\n",
    "import random\n",
    "random.seed(seed)\n",
    "#Start by randomising dominant sample list before partitioning\n",
    "rneglist = neglist\n",
    "random.shuffle(rneglist)\n",
    "#Creates partitions of dominant data each the size of non dominant data\n",
    "loops = 0\n",
    "partitions = []\n",
    "currpart = []\n",
    "for value in rneglist:\n",
    "    currpart.append(value)\n",
    "    loops += 1\n",
    "    if loops == posvals:\n",
    "        partitions.append(currpart)\n",
    "        currpart = []\n",
    "        loops = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae82d19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create models for each partition\n",
    "datasets = []\n",
    "for part in partitions:\n",
    "    newframe = pd.DataFrame()\n",
    "    for item in poslist:\n",
    "        newframe = pd.concat([newframe, df.iloc[item]], axis = 1)\n",
    "    for value in part:\n",
    "        newframe = pd.concat([newframe, df.iloc[value]], axis = 1)\n",
    "    newframe = newframe.transpose()\n",
    "    #newframe.drop(columns=['SMILES'], inplace=True)\n",
    "    \n",
    "    datasets.append(newframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fbbb53",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Model dev on each partition\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "sys.path.insert(1, '/Users/james/Documents/Honours/Python')\n",
    "from Function_Repo import metriccalc \n",
    "iter = 0\n",
    "finalresults = []\n",
    "for df in datasets:\n",
    "    df = df.dropna()\n",
    "    dfarray = df.to_numpy()\n",
    "\n",
    "    dfarray, tempset = train_test_split(dfarray, test_size=0.2, \n",
    "                                        random_state=seed, stratify = df['Toxicity_Value'])\n",
    "\n",
    "    size = len(dfarray) / 5\n",
    "    splitsize = math.ceil(size)\n",
    "    empty = [[] for _ in range(5)]\n",
    "    splits = []\n",
    "    for list in empty:\n",
    "        splits.append(list)\n",
    "\n",
    "    loops = 0\n",
    "    currsplit = 0\n",
    "    #Results in a list of 5 lists that each contain 1/5 of the targetdata\n",
    "    for row in dfarray:\n",
    "        splits[currsplit].append(row)\n",
    "        if loops == splitsize:\n",
    "            loops = 0\n",
    "            currsplit = currsplit + 1\n",
    "        loops = loops + 1\n",
    "\n",
    "    folds = []\n",
    "    for split in splits:\n",
    "        temp = pd.DataFrame(split)\n",
    "        folds.append(temp)\n",
    "\n",
    "    model_list = []\n",
    "    validlist = []\n",
    "    totalmetrics = []\n",
    "    testdat = []\n",
    "    #For loop that uses each fold once for valid/testing and the rest for training\n",
    "    #Each 'split' in the range corresponds to the set used for test/validation with the other 4 for training\n",
    "    iteration = 1\n",
    "    print('========================================')\n",
    "    print('For Partition', iter)\n",
    "    for split in range(0,5):\n",
    "        #Set creation\n",
    "        trainlist = [df for i, df in enumerate(folds) if i != split]\n",
    "        trainset = pd.concat(trainlist, axis=0)\n",
    "        testset, validset = train_test_split(folds[split], test_size=0.5, random_state=seed)\n",
    "\n",
    "        ytrain = trainset[0].values\n",
    "        xtrain = trainset.iloc[:, 1:]\n",
    "\n",
    "        ytest = testset[0].values\n",
    "        xtest = testset.iloc[:, 1:]\n",
    "\n",
    "        yvalid = validset[0].values\n",
    "        xvalid = validset.iloc[:, 1:]\n",
    "\n",
    "        #lists of metric values\n",
    "        mcclist = []\n",
    "        bestmetrics = 1\n",
    "        maxval = 0\n",
    "        for mtry in range(1, 50):\n",
    "            #using mtry as the adjusted hyperparameter creates a series of random forests\n",
    "            rf = RandomForestClassifier(n_estimators=mtry, criterion='entropy', max_depth=None, \n",
    "                                    min_samples_split=2, min_samples_leaf=1, \n",
    "                                    min_weight_fraction_leaf=0.0, max_features='sqrt', \n",
    "                                    max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "                                    bootstrap=True, oob_score=False, n_jobs= 4, random_state=seed, \n",
    "                                    verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
    "\n",
    "            model= rf.fit(xtrain, ytrain)\n",
    "            preds = model.predict(xtest)\n",
    "            #calculate metric (mcc)\n",
    "            mcc = metriccalc(preds, ytest)[12]\n",
    "            mcclist.append(mcc)\n",
    "            if mcc > maxval:\n",
    "                maxval = mcc\n",
    "                bestmetrics = mtry\n",
    "        #store best model for the given fold and plot the metric vs mcc value\n",
    "        rf = RandomForestClassifier(n_estimators=bestmetrics, criterion='entropy', max_depth=None, \n",
    "                                    min_samples_split=2, min_samples_leaf=1, \n",
    "                                    min_weight_fraction_leaf=0.0, max_features='sqrt', \n",
    "                                    max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "                                    bootstrap=True, oob_score=False, n_jobs= 4, random_state=seed, \n",
    "                                    verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
    "        model_list.append(rf)\n",
    "        testdat.append(maxval)\n",
    "        totalmetrics.append(mcclist)\n",
    "\n",
    "        #check models onto validation set, printing various metrics\n",
    "        model= rf.fit(xtrain, ytrain)\n",
    "        preds = model.predict(xvalid)\n",
    "        results = metriccalc(preds, yvalid)\n",
    "        validlist.append(results)\n",
    "        print('for fold', split + 1, 'test set mcc of', maxval, 'valid set mcc of', results[12])\n",
    "\n",
    "        iteration = iteration + 1\n",
    "\n",
    "        #get x and y values for the final validation set\n",
    "\n",
    "    toxvals = []\n",
    "    fingerprints = []\n",
    "    for row in tempset:\n",
    "        toxvals.append(row[0])\n",
    "        fingerprints.append(row[1:])\n",
    "\n",
    "    #calculates consensus of models on each fingerprint in the final validation set\n",
    "    consensuslist = []\n",
    "    predictions = []\n",
    "    for fp in fingerprints:\n",
    "        consensus = -1\n",
    "        fp = fp.reshape(1, -1)\n",
    "        #appends each model's prediction to a list\n",
    "        predictions = []\n",
    "        predlist = []\n",
    "        for model in model_list:\n",
    "            preds = model.predict(fp)\n",
    "            predictions.append(preds)\n",
    "            predlist.append(preds)\n",
    "        predictions.append(predlist)\n",
    "\n",
    "        #finds number of 0s in the prediction list\n",
    "        zercount = 0\n",
    "        for num in predictions:\n",
    "            if num == 0:\n",
    "                zercount = zercount + 1\n",
    "        #as there are 5 models, if there are less than 3 0s predicted, the consensus is 1\n",
    "        if zercount < 3:\n",
    "            consensus = 1\n",
    "        else:\n",
    "            consensus = 0\n",
    "        consensuslist.append(consensus)\n",
    "    #calculate and print metrics\n",
    "    results = metriccalc(consensuslist, toxvals)\n",
    "    print('\\nvalidation metrics of:')\n",
    "    print('positives in data', results[0])\n",
    "    print('negatives in data', results[1])\n",
    "    print('net accuracy =', results[6])\n",
    "    print('mcc =',results[12])\n",
    "    \n",
    "    finalresults.append(results[12])\n",
    "    iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474b63ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(finalresults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef7bd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As can be seen this form of class balancing is working well\n",
    "finalresults"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
