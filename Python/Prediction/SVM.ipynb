{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1558c791",
   "metadata": {},
   "outputs": [],
   "source": [
    "#30/5/24 For the implementaion of Support Vector Machine Prediction in Python for Toxicity Prediction\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#Data import\n",
    "targetdata = pd.read_csv('/Users/james/Documents/Honours/Data/Targetdata/autoencdata/dtargetautoencdata.csv')\n",
    "#Creating test/train splits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainset, testset = train_test_split(targetdata, test_size=0.2, random_state=82)\n",
    "#Converts Toxicity Values to a list\n",
    "temp = trainset['Toxicity_Value']#.to_list\n",
    "ytrain = []\n",
    "for val in temp:\n",
    "    ytrain.append(val)\n",
    "ytest = []\n",
    "temp = testset['Toxicity_Value']#.to_list\n",
    "for val in temp:\n",
    "    ytest.append(val)\n",
    "#Converts encoded drug target values to an array\n",
    "xtrain = trainset.iloc[:, 1:]\n",
    "xtest = testset.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bbbaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "SVM = svm.SVC(C=1, kernel='poly', degree=10, gamma='scale', \n",
    "              coef0=0.0, shrinking=True, probability=False, \n",
    "              tol=0.001, cache_size=200, class_weight=None, \n",
    "              verbose=False, max_iter=-1, decision_function_shape='ovr', \n",
    "              break_ties=False, random_state=None)\n",
    "model= SVM.fit(xtrain, ytrain)\n",
    "preds = model.predict(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628f2569",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for items in preds:\n",
    "    if items != 0:\n",
    "        print(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48812906",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generic Metric testing for a given threshold\n",
    "import math\n",
    "correctcount = 0\n",
    "fpcount = 0\n",
    "tpcount = 0\n",
    "tncount = 0\n",
    "fncount = 0\n",
    "testpos = 0\n",
    "testneg = 0\n",
    "\n",
    "iterations = 0\n",
    "for value in preds:\n",
    "    testscore = ytrain[iterations]\n",
    "    if value == 1:\n",
    "        if testscore != 0:\n",
    "            testpos = testpos + 1\n",
    "            correctcount = correctcount + 1\n",
    "            tpcount = tpcount + 1\n",
    "        else:\n",
    "            fpcount = fpcount + 1\n",
    "            testneg = testneg + 1\n",
    "    else:\n",
    "        if testscore != 0:\n",
    "            testpos = testpos + 1\n",
    "            fncount = fncount + 1\n",
    "        else:\n",
    "            testneg = testneg + 1\n",
    "            correctcount = correctcount + 1\n",
    "            tncount = tncount + 1\n",
    "\n",
    "    iterations = iterations + 1\n",
    "\n",
    "\n",
    "print('positives in data', testpos)\n",
    "print('negatives in data', testneg, '\\n')\n",
    "\n",
    "print('fn count =', fncount)\n",
    "print('tn count =', tncount)\n",
    "\n",
    "print('tp count =', tpcount)\n",
    "print('fp count =', fpcount, '\\n')\n",
    "\n",
    "netfn = fncount / (fncount + tncount)\n",
    "nettn = tncount / (fncount + tncount)\n",
    "netacc = correctcount / (fpcount + fncount + tpcount + tncount)\n",
    "posacc = tpcount / testpos\n",
    "negacc = tncount / testneg\n",
    "netfp = fpcount / (fpcount + tpcount)\n",
    "nettp = tpcount / (tpcount + fpcount)\n",
    "\n",
    "print('net accuracy =', netacc)\n",
    "print('positive accuracy =', posacc)\n",
    "print('negative accuracy =', negacc, '\\n')\n",
    "\n",
    "fpr = fpcount / (fpcount + tncount)\n",
    "tpr = tpcount / (tpcount + fncount)\n",
    "\n",
    "print('fpr =', fpr)\n",
    "print('tpr =', tpr, '\\n')\n",
    "\n",
    "f1 = (2 * tpcount) / ((2 * tpcount) + fpcount + fncount)\n",
    "print('f1 score =',f1)\n",
    "\n",
    "tp = tpcount\n",
    "fp = fpcount\n",
    "tn = tncount\n",
    "fn = fncount\n",
    "\n",
    "mcc = ((tp * tn) - (fp * fn)) / math.sqrt((fp + tn) * (tp + fp) * (tp + fn) * (tn + fn))\n",
    "\n",
    "print('mcc =',mcc)\n",
    "\n",
    "temp = (( ( (tp + fp) * (fp + tn) ) + ( (tp + fn) * (fn + tn) ) ))\n",
    "kapp =  ( 2 * ((tp * tn) - (fn * fp)) ) / temp\n",
    "\n",
    "print('cohen Kappa =',kapp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febc5ba2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "poly, degree = 5\n",
    "\n",
    "positives in data 4295\n",
    "negatives in data 6300 \n",
    "\n",
    "fn count = 4203\n",
    "tn count = 6250\n",
    "tp count = 92\n",
    "fp count = 50 \n",
    "\n",
    "net accuracy = 0.5985842378480415\n",
    "positive accuracy = 0.02142025611175786\n",
    "negative accuracy = 0.9920634920634921 \n",
    "\n",
    "fpr = 0.007936507936507936\n",
    "tpr = 0.02142025611175786 \n",
    "\n",
    "f1 score = 0.041469461347757496\n",
    "mcc = 0.057570214075721715\n",
    "cohen Kappa = 0.01593571205738516"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
