metric=metric, tuneGrid=tunegrid,
trControl=control, na.action = na.exclude)
custom
plot(custom)
RMSE(custom, headata$Toxicity_Value)
predict(custom, headata)
RMSE((predict(custom, headata))), headata$Toxicity_Value)
bing <- predict(custom, headata)
RMSE(bing, headata$Toxicity_Value)
View(headtest)
View(headtrain)
library(readr)
UMAPdata <- read_csv("Documents/Honours/Python/Preprocessing/Notebooks/UMAPdata.csv")
View(UMAPdata)
#Data reading
#endodata <- read_csv("Documents/test/caret_stuff/final.csv")
endodata <- UMAPdata[,2:]
#Data reading
#endodata <- read_csv("Documents/test/caret_stuff/final.csv")
endodata <- UMAPdata
library(readr)
UMAPdata <- read_csv("Documents/Honours/Python/Preprocessing/Notebooks/UMAPdata.csv")
View(UMAPdata)
#Data reading
#endodata <- read_csv("Documents/test/caret_stuff/final.csv")
endodata <- UMAPdata
#Selecting data sample from set (~12000 datapoints)
headata <- sample_n(endodata[,3:(ncol(endodata))], 1000)
library(caret)
library(mlbench)
library(randomForest)
library(dplyr)
library(ada)
library(parallel)
library(doParallel)
seed <- 81
set.seed(seed)
#Data reading
#endodata <- read_csv("Documents/test/caret_stuff/final.csv")
endodata <- UMAPdata
#Selecting data sample from set (~12000 datapoints)
headata <- sample_n(endodata[,3:(ncol(endodata))], 1000)
#Removes Null cells
#headata <- headata[, colSums(is.na(headata)) == 0]
headata$Toxicity_Value = as.factor(headata$Toxicity_Value)
deepnormspedata$Toxicity_Value = as.factor(deepnormspedata$Toxicity_Value)
#Removes Duplicate columns
#As each character in a SMILE is its own data point, if the longest SMILE is not
#In the sample, the extra columns need removing
duperemove <- function(data) {
dupecol <- sapply(data, function(col) length(unique(col)) == 1)
data[, !dupecol, drop = FALSE]
}
headata <- duperemove(headata)
colcount <- ncol(headata)
headsamp <- sample(1:nrow(headata), 0.8 * nrow(headata))
headtest <- headata[-headsamp,]
headtrain <- headata[headsamp,]
headtest <- duperemove(headtest)
headtrain <- duperemove(headtrain)
colcount <- ncol(headtrain)
x <- headtrain[,2:colcount]
y <- headtrain$Toxicity_Value
control <- trainControl(method="repeatedcv", number=10, repeats=3)
metric <- "Accuracy"
set.seed(seed)
mtry <- 12
tunegrid <- expand.grid(.mtry=mtry)
#Custom Algo creation
#Code snippet taken from "https://machinelearningmastery.com/tune-machine-learning-algorithms-in-r/"
#*Temporary, to be rewritten and adjusted for usage
customRF <- list(type = "Classification", library = "randomForest", loop = NULL)
customRF$parameters <- data.frame(parameter = c("mtry", "ntree"), class = rep("numeric", 2), label = c("mtry", "ntree"))
customRF$grid <- function(x, y, len = NULL, search = "grid") {}
customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
randomForest(x, y, mtry = param$mtry, ntree=param$ntree, ...)
}
customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata)
customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata, type = "prob")
customRF$sort <- function(x) x[order(x[,1]),]
customRF$levels <- function(x) x$classes
control <- trainControl(method="repeatedcv", number=10, repeats=3)
tunegrid <- expand.grid(.mtry=c(5:10), .ntree=c(125, 150, 175, 200))
set.seed(seed)
custom <- train(Toxicity_Value~., data=headata, method=customRF,
metric=metric, tuneGrid=tunegrid,
trControl=control, na.action = na.exclude)
custom
plot(custom)
library(readr)
UMAPdata <- read_csv("Documents/Honours/Python/Preprocessing/Notebooks/UMAPdata.csv")
View(UMAPdata)
#Data reading
#endodata <- read_csv("Documents/test/caret_stuff/final.csv")
endodata <- UMAPdata
#Selecting data sample from set (~12000 datapoints)
headata <- sample_n(endodata[,3:(ncol(endodata))], 1000)
#Removes Null cells
#headata <- headata[, colSums(is.na(headata)) == 0]
headata$Toxicity_Value = as.factor(headata$Toxicity_Value)
deepnormspedata$Toxicity_Value = as.factor(deepnormspedata$Toxicity_Value)
#Removes Duplicate columns
#As each character in a SMILE is its own data point, if the longest SMILE is not
#In the sample, the extra columns need removing
duperemove <- function(data) {
dupecol <- sapply(data, function(col) length(unique(col)) == 1)
data[, !dupecol, drop = FALSE]
}
headata <- duperemove(headata)
colcount <- ncol(headata)
headsamp <- sample(1:nrow(headata), 0.8 * nrow(headata))
headtest <- headata[-headsamp,]
headtrain <- headata[headsamp,]
headtest <- duperemove(headtest)
headtrain <- duperemove(headtrain)
colcount <- ncol(headtrain)
x <- headtrain[,2:colcount]
y <- headtrain$Toxicity_Value
control <- trainControl(method="repeatedcv", number=10, repeats=3)
metric <- "Accuracy"
set.seed(seed)
control <- trainControl(method="repeatedcv", number=10, repeats=3)
tunegrid <- expand.grid(.mtry=c(5:10), .ntree=c(125, 150, 175, 200))
set.seed(seed)
custom <- train(Toxicity_Value~., data=headata, method=customRF,
metric=metric, tuneGrid=tunegrid,
trControl=control, na.action = na.exclude)
custom
plot(custom)
View(deepnormspedata)
#Data reading
#endodata <- read_csv("Documents/test/caret_stuff/final.csv")
endodata <- deepnormspedata
#Selecting data sample from set (~12000 datapoints)
headata <- sample_n(endodata[,2:(ncol(endodata))], 1000)
#Removes Null cells
#headata <- headata[, colSums(is.na(headata)) == 0]
headata$Toxicity_Value = as.factor(headata$Toxicity_Value)
deepnormspedata$Toxicity_Value = as.factor(deepnormspedata$Toxicity_Value)
#Removes Duplicate columns
#As each character in a SMILE is its own data point, if the longest SMILE is not
#In the sample, the extra columns need removing
duperemove <- function(data) {
dupecol <- sapply(data, function(col) length(unique(col)) == 1)
data[, !dupecol, drop = FALSE]
}
headata <- duperemove(headata)
colcount <- ncol(headata)
headsamp <- sample(1:nrow(headata), 0.8 * nrow(headata))
headtest <- headata[-headsamp,]
headtrain <- headata[headsamp,]
headtest <- duperemove(headtest)
headtrain <- duperemove(headtrain)
colcount <- ncol(headtrain)
x <- headtrain[,2:colcount]
y <- headtrain$Toxicity_Value
control <- trainControl(method="repeatedcv", number=10, repeats=3)
custom <- train(Toxicity_Value~., data=headata, method=customRF,
metric=metric, tuneGrid=tunegrid,
trControl=control, na.action = na.exclude)
custom
plot(custom)
QuickGO.annotations.5462327785895.20240523 <- read.delim("~/Downloads/QuickGO-annotations-5462327785895-20240523.tsv")
View(QuickGO.annotations.5462327785895.20240523)
library(readr)
dtargetautoencdata <- read_csv("Documents/Honours/Data/Targetdata/autoencdata/dtargetautoencdata.csv")
View(dtargetautoencdata)
gc()
library(caret)
library(readr)
dtargetautoencdata <- read_csv("Documents/Honours/Data/Targetdata/autoencdata/dtargetautoencdata.csv")
View(dtargetautoencdata)
library(mlbench)
library(randomForest)
library(parallel)
library(doParallel)
library(dplyr)
library(Metrics)
library(pROC)
setwd("~/Documents/Honours/R/Algo_Usage")
cl <- makePSOCKcluster(4)
registerDoParallel(cl)
seed <- 81
set.seed(seed)
#Data Reading, make sure to change for each set
#df <- read_csv("datasets/UMAPdata.csv")
df <- dtargetautoencdata
#Sampling for testing
df <- sample_n(df[,3:(ncol(df))], 1000)
sampleset <- createDataPartition(df$Toxicity_Value, p=0.8, list=FALSE)
#Convert Toxicity_Value into a factor for the algorithm
#Numerical Binary (1,0) values are also altered to Categorical (T, F)
df$Toxicity_Value = as.factor(df$Toxicity_Value)
df$Toxicity_Value <- ifelse(df$Toxicity_Value == 1, "T", "F")
sampleset <- createDataPartition(df$Toxicity_Values, p=0.8, list=FALSE)
#Data Reading, make sure to change for each set
#df <- read_csv("datasets/UMAPdata.csv")
df <- dtargetautoencdata
#Sampling for testing
df <- sample_n(df[,3:(ncol(df))], 1000)
sampleset <- createDataPartition(df$Toxicity_Values, p=0.8, list=FALSE)
View(df)
#Sampling for testing
df <- sample_n(df[,1:(ncol(df))], 1000)
View(df)
#Sampling for testing
df <- sample_n(df[,0:(ncol(df))], 1000)
sampleset <- createDataPartition(df$Toxicity_Values, p=0.8, list=FALSE)
View(df)
#Data Reading, make sure to change for each set
#df <- read_csv("datasets/UMAPdata.csv")
df <- dtargetautoencdata
#Sampling for testing
df <- sample_n(df[,0:(ncol(df))], 1000)
View(df)
sampleset <- createDataPartition(df$Toxicity_Values, p=0.8, list=FALSE)
#Convert Toxicity_Value into a factor for the algorithm
#Numerical Binary (1,0) values are also altered to Categorical (T, F)
df$Toxicity_Value = as.factor(df$Toxicity_Value)
df$Toxicity_Value <- ifelse(df$Toxicity_Value == 1, "T", "F")
#Creating test and train sets
testset <- df[-sampleset,]
library(readr)
dtargetautoencdata <- read_csv("~/Documents/Honours/Data/Targetdata/autoencdata/dtargetautoencdata.csv")
View(dtargetautoencdata)
#Data Reading, make sure to change for each set
#df <- read_csv("datasets/UMAPdata.csv")
df <- dtargetautoencdata
#Sampling for testing
df <- sample_n(df[,0:(ncol(df))], 1000)
sampleset <- createDataPartition(df$Toxicity_Value, p=0.8, list=FALSE)
#Convert Toxicity_Value into a factor for the algorithm
#Numerical Binary (1,0) values are also altered to Categorical (T, F)
df$Toxicity_Value = as.factor(df$Toxicity_Value)
df$Toxicity_Value <- ifelse(df$Toxicity_Value == 1, "T", "F")
#Creating test and train sets
testset <- df[-sampleset,]
trainset <- df[sampleset,]
x <- trainset#[,2:ncol(trainset)]
y <- trainset$Toxicity_Value
#Parameter setting
#test mtry = 5, 10, 50, 100, 250, 500
candidates = c(5, 10, 50, 100, 250)
#test ntree = 500, 1000, 2500
treecount = c(1000)
#Testing a range of parameters
metric <- "Accuracy"
#Control tests for ROC, Sensitivity, Specificity
control <- trainControl(method="cv", number=10,
summaryFunction=twoClassSummary,
classProbs=TRUE,
savePredictions = 'all',
allowParallel=TRUE)
tunegrid <- expand.grid(.mtry=candidates)
set.seed(seed)
#Trains the model on data using parameters set
metric <- "ROC"
set.seed(seed)
tunegrid <- expand.grid(.mtry=candidates)
start.time <- Sys.time()
custom <- train(Toxicity_Value~., data=x, method="rf",
metric=metric, tuneGrid=tunegrid, trControl=control,
ntree=treecount, na.action = na.exclude)
end.time <- Sys.time()
time.taken <- round(end.time - start.time,2)
time.taken
#Plot and View Data
custom
#Predict on Test Set
predout = predict(custom, testset)
#Tests accuracy of model on the Test Set
length = length(testset$Toxicity_Value)
counts = 0
for (i in 1:length) {
if (testset$Toxicity_Value[i] == predout[i]) {
counts <- counts + 1
}
}
acc = counts/nrow(testset)
print(paste("Accuracy = ", acc))
#Determines Cohen's Kappa Coefficient of Model
testset$Toxicity_Value = as.factor(testset$Toxicity_Value)
postResample(pred = predout, obs = testset$Toxicity_Value)
#Converts Toxicity_Value Data back to numerical to calculate RMSE
df$Toxicity_Value <- ifelse(df$Toxicity_Value == 1, "T", "F")
binary_testset <- ifelse(testset$Toxicity_Value == 'T', 1, 0)
binary_preds <- ifelse(predout == 'T', 1, 0)
#Determines RMSE of model
RMSE <- rmse(binary_testset, binary_preds)
#Output all results to text
#Change output file depending on inputs
sink(file = 'autoencdataRF.txt')
print('from autoencdata.csv')
print(paste("ntree = ", treecount))
print(paste("mtry = ", candidates))
custom
postResample(pred = predout, obs = testset$Toxicity_Value)
print(paste("Accuracy = ", acc))
print(paste("RMSE = ", RMSE))
print(time.taken)
sink()
print(paste("ntree = ", treecount))
print(paste("mtry = ", candidates))
custom
postResample(pred = predout, obs = testset$Toxicity_Value)
print(paste("Accuracy = ", acc))
print(paste("RMSE = ", RMSE))
print(time.taken)
#test ntree = 500, 1000, 2500
treecount = c(2000)
#Testing a range of parameters
metric <- "Accuracy"
#Control tests for ROC, Sensitivity, Specificity
control <- trainControl(method="cv", number=10,
summaryFunction=twoClassSummary,
classProbs=TRUE,
savePredictions = 'all',
allowParallel=TRUE)
tunegrid <- expand.grid(.mtry=candidates)
set.seed(seed)
#Trains the model on data using parameters set
metric <- "ROC"
set.seed(seed)
tunegrid <- expand.grid(.mtry=candidates)
start.time <- Sys.time()
custom <- train(Toxicity_Value~., data=x, method="rf",
metric=metric, tuneGrid=tunegrid, trControl=control,
ntree=treecount, na.action = na.exclude)
end.time <- Sys.time()
time.taken <- round(end.time - start.time,2)
time.taken
#Plot and View Data
custom
#Predict on Test Set
predout = predict(custom, testset)
#Tests accuracy of model on the Test Set
length = length(testset$Toxicity_Value)
counts = 0
for (i in 1:length) {
if (testset$Toxicity_Value[i] == predout[i]) {
counts <- counts + 1
}
}
acc = counts/nrow(testset)
print(paste("Accuracy = ", acc))
#Determines Cohen's Kappa Coefficient of Model
testset$Toxicity_Value = as.factor(testset$Toxicity_Value)
postResample(pred = predout, obs = testset$Toxicity_Value)
#Converts Toxicity_Value Data back to numerical to calculate RMSE
df$Toxicity_Value <- ifelse(df$Toxicity_Value == 1, "T", "F")
binary_testset <- ifelse(testset$Toxicity_Value == 'T', 1, 0)
binary_preds <- ifelse(predout == 'T', 1, 0)
#Determines RMSE of model
RMSE <- rmse(binary_testset, binary_preds)
#Output all results to text
#Change output file depending on inputs
sink(file = 'autoencdataRF.txt')
print(paste("ntree = ", treecount))
print(paste("mtry = ", candidates))
custom
postResample(pred = predout, obs = testset$Toxicity_Value)
print(paste("Accuracy = ", acc))
print(paste("RMSE = ", RMSE))
print(time.taken)
#Output all results to text
#Change output file depending on inputs
#sink(file = 'autoencdataRF.txt')
print('from autoencdata.csv')
sink()
#Output all results to text
#Change output file depending on inputs
#sink(file = 'autoencdataRF.txt')
print('from autoencdata.csv')
print(paste("ntree = ", treecount))
print(paste("mtry = ", candidates))
custom
postResample(pred = predout, obs = testset$Toxicity_Value)
#Custom Algo creation
#Code snippet taken from "https://machinelearningmastery.com/tune-machine-learning-algorithms-in-r/"
#*Temporary, to be rewritten and adjusted for usage
customRF <- list(type = "Classification", library = "randomForest", loop = NULL)
customRF$parameters <- data.frame(parameter = c("mtry", "ntree"), class = rep("numeric", 2), label = c("mtry", "ntree"))
customRF$grid <- function(x, y, len = NULL, search = "grid") {}
customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
randomForest(x, y, mtry = param$mtry, ntree=param$ntree, ...)
}
customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata)
customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata, type = "prob")
customRF$sort <- function(x) x[order(x[,1]),]
customRF$levels <- function(x) x$classes
control <- trainControl(method="repeatedcv", number=10, repeats=3)
tunegrid <- expand.grid(.mtry=c(5:10), .ntree=c(125, 150, 175, 200))
set.seed(seed)
custom <- train(Toxicity_Value~., data=x, method=customRF,
metric=metric, tuneGrid=tunegrid,
trControl=control, na.action = na.exclude)
control <- trainControl(method="repeatedcv", number=10, repeats=3, classProbs = TRUE)
tunegrid <- expand.grid(.mtry=c(5:10), .ntree=c(125, 150, 175, 200))
set.seed(seed)
custom <- train(Toxicity_Value~., data=x, method=customRF,
metric=metric, tuneGrid=tunegrid,
trControl=control, na.action = na.exclude)
stopCluster(cl)
custom <- train(Toxicity_Value~., data=x, method=customRF,
metric=metric, tuneGrid=tunegrid,
trControl=control, na.action = na.exclude)
library(caret)
library(mlbench)
library(randomForest)
library(parallel)
library(doParallel)
library(dplyr)
library(Metrics)
library(pROC)
setwd("~/Documents/Honours/R/Algo_Usage")
seed <- 81
set.seed(seed)
#Data Reading, make sure to change for each set
#df <- read_csv("datasets/UMAPdata.csv")
df <- dtargetautoencdata
#Sampling for testing
df <- sample_n(df[,0:(ncol(df))], 1000)
sampleset <- createDataPartition(df$Toxicity_Value, p=0.8, list=FALSE)
#Convert Toxicity_Value into a factor for the algorithm
#Numerical Binary (1,0) values are also altered to Categorical (T, F)
df$Toxicity_Value = as.factor(df$Toxicity_Value)
df$Toxicity_Value <- ifelse(df$Toxicity_Value == 1, "T", "F")
#Creating test and train sets
testset <- df[-sampleset,]
trainset <- df[sampleset,]
library(caret)
library(mlbench)
library(randomForest)
library(parallel)
library(doParallel)
library(dplyr)
library(Metrics)
library(pROC)
setwd("~/Documents/Honours/R/Algo_Usage")
seed <- 81
set.seed(seed)
#Data Reading, make sure to change for each set
#df <- read_csv("datasets/UMAPdata.csv")
df <- dtargetautoencdata
library(readr)
dtargetautoencdata <- read_csv("~/Documents/Honours/Data/Targetdata/autoencdata/dtargetautoencdata.csv")
View(dtargetautoencdata)
#Sampling for testing
df <- sample_n(df[,0:(ncol(df))], 1000)
sampleset <- createDataPartition(df$Toxicity_Value, p=0.8, list=FALSE)
#Convert Toxicity_Value into a factor for the algorithm
#Numerical Binary (1,0) values are also altered to Categorical (T, F)
df$Toxicity_Value = as.factor(df$Toxicity_Value)
df$Toxicity_Value <- ifelse(df$Toxicity_Value == 1, "T", "F")
#Creating test and train sets
testset <- df[-sampleset,]
#Data Reading, make sure to change for each set
#df <- read_csv("datasets/UMAPdata.csv")
df <- dtargetautoencdata
#Sampling for testing
df <- sample_n(df[,0:(ncol(df))], 1000)
sampleset <- createDataPartition(df$Toxicity_Value, p=0.8, list=FALSE)
#Convert Toxicity_Value into a factor for the algorithm
#Numerical Binary (1,0) values are also altered to Categorical (T, F)
df$Toxicity_Value = as.factor(df$Toxicity_Value)
df$Toxicity_Value <- ifelse(df$Toxicity_Value == 1, "T", "F")
#Creating test and train sets
testset <- df[-sampleset,]
trainset <- df[sampleset,]
x <- trainset#[,2:ncol(trainset)]
y <- trainset$Toxicity_Value
#Parameter setting
#test mtry = 5, 10, 50, 100, 250, 500
candidates = c(5, 10, 50, 100, 250)
#test ntree = 500, 1000, 2500
treecount = c(2000)
#Testing a range of parameters
metric <- "Accuracy"
#Control tests for ROC, Sensitivity, Specificity
control <- trainControl(method="cv", number=10,
summaryFunction=twoClassSummary,
classProbs=TRUE,
savePredictions = 'all',
allowParallel=TRUE)
tunegrid <- expand.grid(.mtry=candidates)
#Custom Algo creation
#Code snippet taken from "https://machinelearningmastery.com/tune-machine-learning-algorithms-in-r/"
#*Temporary, to be rewritten and adjusted for usage
customRF <- list(type = "Classification", library = "randomForest", loop = NULL)
customRF$parameters <- data.frame(parameter = c("mtry", "ntree"), class = rep("numeric", 2), label = c("mtry", "ntree"))
customRF$grid <- function(x, y, len = NULL, search = "grid") {}
customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
randomForest(x, y, mtry = param$mtry, ntree=param$ntree, ...)
}
customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata)
customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata, type = "prob")
customRF$sort <- function(x) x[order(x[,1]),]
customRF$levels <- function(x) x$classes
control <- trainControl(method="repeatedcv", number=10, repeats=3, classProbs = TRUE)
tunegrid <- expand.grid(.mtry=c(5:10), .ntree=c(125, 150, 175, 200))
set.seed(seed)
custom <- train(Toxicity_Value~., data=x, method=customRF,
metric=metric, tuneGrid=tunegrid,
trControl=control, na.action = na.exclude)
custom
plot(custom)
