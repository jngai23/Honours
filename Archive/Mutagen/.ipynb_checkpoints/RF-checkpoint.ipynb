{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8806cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6/6/24\n",
    "#RF testing using morganfp data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#Data import\n",
    "targetdata = pd.read_csv('/Users/james/Documents/Honours/Data/structdata/Mutagen/mutagenMorganfp.csv')\n",
    "#Creating test/train splits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainset, testset = train_test_split(targetdata, test_size=0.2, random_state=82)\n",
    "#Converts Toxicity Values to a list\n",
    "temp = trainset['Toxicity_Values']#.to_list\n",
    "ytrain = []\n",
    "for val in temp:\n",
    "    ytrain.append(val)\n",
    "ytest = []\n",
    "temp = testset['Toxicity_Values']#.to_list\n",
    "for val in temp:\n",
    "    ytest.append(val)\n",
    "#Converts encoded drug target values to an array\n",
    "xtrain = trainset.iloc[:, 2:]\n",
    "xtest = testset.iloc[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8b96e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "model= rf.fit(xtrain, ytrain)\n",
    "preds = model.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ad093e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "mtry = 50\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=1, criterion='entropy', max_depth=None,\n",
    "                                            min_samples_split=8, min_samples_leaf=1, \n",
    "                                            min_weight_fraction_leaf=0.0, max_features=3, \n",
    "                                            max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "                                            bootstrap=True, oob_score=False, n_jobs= 4, random_state=81, \n",
    "                                            verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0,\n",
    "                                            max_samples=None)\n",
    "\n",
    "model= rf.fit(xtrain, ytrain)\n",
    "preds = model.predict(xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0e28446",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1093621610.py, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 16\u001b[0;36m\u001b[0m\n\u001b[0;31m    activevar =\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Metric curve creation (Recycled from autoencoder doc)\n",
    "#Mostly to get a feel for how each metric impacts the tree\n",
    "#Prototype for the creation of a hyperparameter finder that loops through each combination of variables\n",
    "\n",
    "mtry = range(1, 30)\n",
    "crite = ['gini', 'entropy', 'log_loss']\n",
    "maxdepth = [None, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "minsampsplit = range(2, 10)\n",
    "minsampleaf = range(1, 10)\n",
    "minleafweightfrac = np.arange(0, 0.5, 0.02)\n",
    "maxfeat = ['sqrt', 'log2', None, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "minpuritydec = np.arange(0, 2, 0.2)\n",
    "maxsamp = [None, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "#Sets active varible\n",
    "activevar = \n",
    "#A list of lists of metrics, the index corresponds to the active variable's index\n",
    "resultlist = []\n",
    "maxval = 0\n",
    "bestmtry = 0\n",
    "for var in activevar:\n",
    "    metriclist = []\n",
    "    for mtry in range(1, 30):\n",
    "        rf = RandomForestClassifier(n_estimators=mtry, criterion='entropy', max_depth=None, \n",
    "                                min_samples_split=9, min_samples_leaf=1, \n",
    "                                min_weight_fraction_leaf=0.0, max_features=9, \n",
    "                                max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "                                bootstrap=True, oob_score=False, n_jobs= 4, random_state=81, \n",
    "                                verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0,\n",
    "                                max_samples=None)\n",
    "\n",
    "        model= rf.fit(xtrain, ytrain)\n",
    "        preds = model.predict(xtest)\n",
    "        newval = metriccalc(preds, ytest)\n",
    "        \n",
    "        metriclist.append(newval)\n",
    "        \n",
    "        if newval > maxval:\n",
    "            maxval = newval\n",
    "            bestmtry = mtry\n",
    "            bestmetric = var\n",
    "        \n",
    "    resultlist.append(metriclist)\n",
    "\n",
    "print('mcc peak of', maxval, 'at mtry =', bestmtry, 'with variable =', bestmetric)\n",
    "\n",
    "loops = 0\n",
    "for list in resultlist:\n",
    "    plt.plot(list, label = activevar[loops])\n",
    "    loops = loops + 1\n",
    "\n",
    "plt.xlabel('mtry')\n",
    "plt.ylabel('mcc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52567ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04cb435",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metric curve creation (Recycled from autoencoder doc)\n",
    "metriclist = []\n",
    "varlist = []\n",
    "\n",
    "crite = ['gini', 'entropy', 'log_loss']\n",
    "mtry = range(1, 30)\n",
    "minsampleaf = range(1, 10)\n",
    "maxfeat = ['sqrt', 'log2', None]\n",
    "\n",
    "for mtry in range(1, 30):\n",
    "    rf = RandomForestClassifier(n_estimators=mtry, criterion=crite[1], max_depth=None, \n",
    "                            min_samples_split=2, min_samples_leaf=1, \n",
    "                            min_weight_fraction_leaf=0.0, max_features='sqrt', \n",
    "                            max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "                            bootstrap=True, oob_score=False, n_jobs= 4, random_state=81, \n",
    "                            verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
    "    \n",
    "    model= rf.fit(xtrain, ytrain)\n",
    "    preds = model.predict(xtest)\n",
    "    \n",
    "    metriclist.append(metriccalc(preds, ytest))\n",
    "    varlist.append(mtry)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "y_values = metriclist\n",
    "x_values = varlist\n",
    "\n",
    "max_y = max(y_values)\n",
    "max_x = x_values[y_values.index(max_y)]\n",
    "\n",
    "print('optimal paramers at y=', max_y, 'x=', max_x)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(x_values, y_values, marker='o', linestyle='-')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Plot of Tuple Data')\n",
    "plt.ylabel('Metric')\n",
    "plt.xlabel('Variable')\n",
    "\n",
    "# Display the plot\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489f7ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gargantuan for loop to test every combination of hyperparameters\n",
    "\n",
    "mtry = range(1, 30)\n",
    "crite = ['gini', 'entropy', 'log_loss']\n",
    "maxdepth = [None, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "minsampsplit = range(2, 10)\n",
    "minsampleaf = range(1, 10)\n",
    "minleafweightfrac = np.arange(0, 0.5, 0.02)\n",
    "maxfeat = ['sqrt', 'log2', None, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "minpuritydec = np.arange(0, 2, 0.2)\n",
    "maxsamp = [None, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "#Sets active varible\n",
    "activevar = \n",
    "#A list of lists of metrics, the index corresponds to the active variable's index\n",
    "maxval = 0\n",
    "bestmetrics = []\n",
    "\n",
    "for mtry in range(1, 30):\n",
    "    for criteria in crite:\n",
    "        for depth in maxdepth:\n",
    "            for sampsplit in minsampsplit:\n",
    "                for sampleaf in minsampleaf:\n",
    "                    for weight in minleafweightfrac:\n",
    "                        for feat in maxfeat:\n",
    "                            for puritydec in minpuritydec:\n",
    "                                for samp in maxsamp:\n",
    "                                    rf = RandomForestClassifier(n_estimators=mtry, criterion=criteria, max_depth=depth, \n",
    "                                                            min_samples_split=sampsplit, min_samples_leaf=sampleaf, \n",
    "                                                            min_weight_fraction_leaf=weight, max_features=feat, \n",
    "                                                            max_leaf_nodes=None, min_impurity_decrease=puritydec, \n",
    "                                                            bootstrap=True, oob_score=False, n_jobs= 4, random_state=81, \n",
    "                                                            verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0,\n",
    "                                                            max_samples=samp)\n",
    "\n",
    "                                    model= rf.fit(xtrain, ytrain)\n",
    "                                    preds = model.predict(xtest)\n",
    "                                    newval = metriccalc(preds, ytest)\n",
    "                                    curmetrics = [mtry, criteria, depth, sampsplit, sampleaf, \n",
    "                                                  weight, feat, puritydec, samp]\n",
    "\n",
    "                                    metriclist.append(newval)\n",
    "\n",
    "                                    if newval > maxval:\n",
    "                                        maxval = newval\n",
    "                                        bestmetrics = curmetrics\n",
    "\n",
    "print('best metrics = ', bestmetrics, 'for mcc of', maxval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a55a5bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate various metricsm, output changes as needed\n",
    "import math\n",
    "def metriccalc(preds, ytrain):\n",
    "    correctcount = 0\n",
    "    fpcount = 0\n",
    "    tpcount = 0\n",
    "    tncount = 0\n",
    "    fncount = 0\n",
    "    testpos = 0\n",
    "    testneg = 0\n",
    "\n",
    "    iterations = 0\n",
    "    for value in preds:\n",
    "        testscore = ytrain[iterations]\n",
    "        if value == 1:\n",
    "            if testscore != 0:\n",
    "                testpos = testpos + 1\n",
    "                correctcount = correctcount + 1\n",
    "                tpcount = tpcount + 1\n",
    "            else:\n",
    "                fpcount = fpcount + 1\n",
    "                testneg = testneg + 1\n",
    "        else:\n",
    "            if testscore != 0:\n",
    "                testpos = testpos + 1\n",
    "                fncount = fncount + 1\n",
    "            else:\n",
    "                testneg = testneg + 1\n",
    "                correctcount = correctcount + 1\n",
    "                tncount = tncount + 1\n",
    "\n",
    "        iterations = iterations + 1\n",
    "\n",
    "    #netfn = fncount / (fncount + tncount)\n",
    "    #nettn = tncount / (fncount + tncount)\n",
    "    #netacc = correctcount / (fpcount + fncount + tpcount + tncount)\n",
    "    #posacc = tpcount / testpos\n",
    "    #negacc = tncount / testneg\n",
    "    #netfp = fpcount / (fpcount + tpcount)\n",
    "    #nettp = tpcount / (tpcount + fpcount)\n",
    "\n",
    "    fpr = fpcount / (fpcount + tncount)\n",
    "    tpr = tpcount / (tpcount + fncount)\n",
    "\n",
    "\n",
    "\n",
    "    f1 = (2 * tpcount) / ((2 * tpcount) + fpcount + fncount)\n",
    "\n",
    "\n",
    "    tp = tpcount\n",
    "    fp = fpcount\n",
    "    tn = tncount\n",
    "    fn = fncount\n",
    "\n",
    "    \n",
    "    temp = math.sqrt((fp + tn) * (tp + fp) * (tp + fn) * (tn + fn))\n",
    "    if temp == 0:\n",
    "        return 0\n",
    "    mcc = ((tp * tn) - (fp * fn)) / temp\n",
    "\n",
    "\n",
    "\n",
    "    temp = (( ( (tp + fp) * (fp + tn) ) + ( (tp + fn) * (fn + tn) ) ))\n",
    "    if temp == 0:\n",
    "        return 0\n",
    "    kapp =  ( 2 * ((tp * tn) - (fn * fp)) ) / temp\n",
    "    \n",
    "    return mcc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5853a1e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mtry = 50 \n",
      "\n",
      "positives in data 815\n",
      "negatives in data 682 \n",
      "\n",
      "fn count = 111\n",
      "tn count = 539\n",
      "tp count = 704\n",
      "fp count = 143 \n",
      "\n",
      "net accuracy = 0.8303273213092852\n",
      "positive accuracy = 0.8638036809815951\n",
      "negative accuracy = 0.7903225806451613 \n",
      "\n",
      "fpr = 0.20967741935483872\n",
      "tpr = 0.8638036809815951 \n",
      "\n",
      "f1 score = 0.8471720818291215\n",
      "mcc = 0.6572554463746911\n",
      "cohen Kappa = 0.6566402144113621\n"
     ]
    }
   ],
   "source": [
    "correctcount = 0\n",
    "fpcount = 0\n",
    "tpcount = 0\n",
    "tncount = 0\n",
    "fncount = 0\n",
    "testpos = 0\n",
    "testneg = 0\n",
    "\n",
    "iterations = 0\n",
    "for value in preds:\n",
    "    testscore = ytest[iterations]\n",
    "    if value == 1:\n",
    "        if testscore != 0:\n",
    "            testpos = testpos + 1\n",
    "            correctcount = correctcount + 1\n",
    "            tpcount = tpcount + 1\n",
    "        else:\n",
    "            fpcount = fpcount + 1\n",
    "            testneg = testneg + 1\n",
    "    else:\n",
    "        if testscore != 0:\n",
    "            testpos = testpos + 1\n",
    "            fncount = fncount + 1\n",
    "        else:\n",
    "            testneg = testneg + 1\n",
    "            correctcount = correctcount + 1\n",
    "            tncount = tncount + 1\n",
    "\n",
    "    iterations = iterations + 1\n",
    "\n",
    "print('mtry =', mtry, '\\n')\n",
    "\n",
    "print('positives in data', testpos)\n",
    "print('negatives in data', testneg, '\\n')\n",
    "\n",
    "print('fn count =', fncount)\n",
    "print('tn count =', tncount)\n",
    "\n",
    "print('tp count =', tpcount)\n",
    "print('fp count =', fpcount, '\\n')\n",
    "\n",
    "netfn = fncount / (fncount + tncount)\n",
    "nettn = tncount / (fncount + tncount)\n",
    "netacc = correctcount / (fpcount + fncount + tpcount + tncount)\n",
    "posacc = tpcount / testpos\n",
    "negacc = tncount / testneg\n",
    "netfp = fpcount / (fpcount + tpcount)\n",
    "nettp = tpcount / (tpcount + fpcount)\n",
    "\n",
    "print('net accuracy =', netacc)\n",
    "print('positive accuracy =', posacc)\n",
    "print('negative accuracy =', negacc, '\\n')\n",
    "\n",
    "fpr = fpcount / (fpcount + tncount)\n",
    "tpr = tpcount / (tpcount + fncount)\n",
    "\n",
    "print('fpr =', fpr)\n",
    "print('tpr =', tpr, '\\n')\n",
    "\n",
    "f1 = (2 * tpcount) / ((2 * tpcount) + fpcount + fncount)\n",
    "print('f1 score =',f1)\n",
    "\n",
    "tp = tpcount\n",
    "fp = fpcount\n",
    "tn = tncount\n",
    "fn = fncount\n",
    "\n",
    "mcc = ((tp * tn) - (fp * fn)) / math.sqrt((fp + tn) * (tp + fp) * (tp + fn) * (tn + fn))\n",
    "\n",
    "print('mcc =',mcc)\n",
    "\n",
    "temp = (( ( (tp + fp) * (fp + tn) ) + ( (tp + fn) * (fn + tn) ) ))\n",
    "kapp =  ( 2 * ((tp * tn) - (fn * fp)) ) / temp\n",
    "\n",
    "print('cohen Kappa =',kapp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
